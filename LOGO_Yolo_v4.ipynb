{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLXr20+JI/aguPuxQEh3xb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSChoo/test1/blob/main/LOGO_Yolo_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWwqHphKtGd1",
        "outputId": "e32f9d2b-3ade-43fa-f667-04270608844e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   902  100   902    0     0    609      0  0:00:01  0:00:01 --:--:--   609\n",
            "100 17.7M  100 17.7M    0     0   9.9M      0  0:00:01  0:00:01 --:--:--  9.9M\n"
          ]
        }
      ],
      "source": [
        "#roboflow data 사용\n",
        "!curl -L -o robo.zip https://app.roboflow.com/ds/zW9DIeMsqX?key=tkuuiRDujl\n",
        "#\"roboflow data\"를 사용하여 데이터를 다운로드하는 명령어입니다.\n",
        "#curl을 사용하여 roboflow.com에서 데이터셋을 다운로드하고, 해당 데이터셋의 키를 사용하여 다운로드합니다.\n",
        "#다운로드된 데이터는 \"robo.zip\" 파일로 저장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset\n",
        "#\"dataset\"이라는 디렉토리를 생성하는 명령어입니다.\n",
        "#이 디렉토리는 데이터셋을 저장하기 위한 폴더로 사용될 수 있습니다."
      ],
      "metadata": {
        "id": "gFOcmrxStIJB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv robo.zip ./dataset\n",
        "#\"robo.zip\" 파일을 \"dataset\" 디렉토리로 이동시키는 명령어입니다.\n",
        "#다운로드한 데이터셋 파일이 \"dataset\" 디렉토리 안에 저장됩니다."
      ],
      "metadata": {
        "id": "mFqhxnqhuJQt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd dataset\n",
        "!unzip -oq robo.zip\n",
        "#\"dataset\" 디렉토리로 이동한 후에 \"robo.zip\" 파일을 압축 해제하는 명령어입니다.\n",
        "#\"robo.zip\" 파일의 내용이 \"dataset\" 디렉토리에 압축 해제됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3DHaYS8uJNR",
        "outputId": "ee618ebe-09ea-4e77-e94b-91a924c6a85a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Yolov5 환경설정\n",
        "# 초기화\n",
        "%cd /content\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "#\"/content\" 디렉토리로 이동한 후에 \"yolov5\"라는 이름으로 GitHub 저장소를 복제하는 명령어입니다.\n",
        "#\"yolov5\" 프로젝트가 \"/content\" 디렉토리에 복제됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkmMbfcXuJKa",
        "outputId": "769fd5cc-59e8-4c8f-ba22-afd4eea3a73e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 15927, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 15927 (delta 20), reused 26 (delta 9), pack-reused 15880\u001b[K\n",
            "Receiving objects: 100% (15927/15927), 14.60 MiB | 25.55 MiB/s, done.\n",
            "Resolving deltas: 100% (10919/10919), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5/\n",
        "!pip install -r requirements.txt\n",
        "#\"/content/yolov5/\" 디렉토리로 이동한 후에 \"requirements.txt\" 파일에 명시된 필수 패키지들을 설치하는 명령어입니다.\n",
        "#필요한 패키지들이 설치되어 프로젝트를 실행할 수 있게 됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYmXVPQwuJHb",
        "outputId": "0a3a6ee8-b1e6-48d7-c050-c44398b6c1c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "Collecting gitpython>=3.1.30 (from -r requirements.txt (line 5))\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.66.1)\n",
            "Collecting ultralytics>=8.0.147 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.0.164-py3-none-any.whl (608 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.9/608.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r requirements.txt (line 15)) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->-r requirements.txt (line 15)) (16.0.6)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.147->-r requirements.txt (line 18)) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5))\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Installing collected packages: smmap, gitdb, gitpython, ultralytics, thop\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.32 smmap-5.0.0 thop-0.1.1.post2209072238 ultralytics-8.0.164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "#현재 작업 디렉토리를 출력하는 명령어입니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v_o8MRcuJES",
        "outputId": "a09534f1-c0dc-4592-c674-44c93c7afb0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat /content/dataset/data.yaml\n",
        "#\"/content/dataset/data.yaml\" 파일의 내용을 출력하는 명령어입니다.\n",
        "#해당 파일의 내용이 출력됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLlUUhCJuJBJ",
        "outputId": "9a206288-5422-4958-840d-7eed8a7fea11"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 4\n",
            "names: ['NG_L', 'NG_R', 'OK_L', 'OK_R']\n",
            "\n",
            "roboflow:\n",
            "  workspace: hs-esyhr\n",
            "  project: logo4-yuhxx\n",
            "  version: 14\n",
            "  license: CC BY 4.0\n",
            "  url: https://universe.roboflow.com/hs-esyhr/logo4-yuhxx/dataset/14"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /\n",
        "from glob import glob\n",
        "train_img_list = glob('/content/dataset/train/images/*.jpg')\n",
        "val_img_list = glob('/content/dataset/valid/images/*.jpg')\n",
        "print(len(train_img_list)), print(len(val_img_list))\n",
        "#현재 작업 디렉토리를 루트 디렉토리로 변경합니다.\n",
        "#glob 모듈을 사용하여 '/content/dataset/train/images/*.jpg' 경로에 해당하는 모든 jpg 파일의 리스트를 가져옵니다.\n",
        "#glob 모듈을 사용하여 '/content/dataset/valid/images/*.jpg' 경로에 해당하는 모든 jpg 파일의 리스트를 가져옵니다.\n",
        "#train_img_list의 길이를 출력합니다.\n",
        "#val_img_list의 길이를 출력합니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFQgHasluI7E",
        "outputId": "03099775-ed5c-4163-c5e7-85ca02f6d79e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "210\n",
            "20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_list[:3]\n",
        "#train_img_list의 처음 3개의 요소가 출력됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCSXH4eIuI4J",
        "outputId": "99f942c0-c1b0-43ce-dcfb-c5282b188ac5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/dataset/train/images/OK_10_png.rf.b236e4abee69b60aed5f1d05cb9b15a0.jpg',\n",
              " '/content/dataset/train/images/OK_10_png.rf.e4f16c011ee5c500f2af37777c9bef2b.jpg',\n",
              " '/content/dataset/train/images/OK_29_png.rf.85f62964f22099442f0a434fbbd5e91d.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/dataset/train.txt', 'w') as f:\n",
        "  f.write('\\n'.join(train_img_list) + '\\n')\n",
        "with open('/content/dataset/val.txt', 'w') as f:\n",
        "  f.write('\\n'.join(val_img_list) + '\\n')\n",
        "#'/content/dataset/train.txt' 파일을 쓰기 모드로 엽니다.\n",
        "#train_img_list의 모든 요소를 개행문자('\\n')로 구분하여 문자열로 변환한 후, 파일에 씁니다.\n",
        "#'/content/dataset/val.txt' 파일을 쓰기 모드로 엽니다.\n",
        "#val_img_list의 모든 요소를 개행문자('\\n')로 구분하여 문자열로 변환한 후, 파일에 씁니다.\n",
        "#train_img_list의 요소들이 'train.txt' 파일에, val_img_list의 요소들이 'val.txt' 파일에 저장됩니다."
      ],
      "metadata": {
        "id": "Lp3JU4iYuI1S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 /content/dataset/train.txt\n",
        "#'train.txt' 파일의 처음 5줄이 출력됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN5AyRcquIyB",
        "outputId": "d38e2cab-de39-4e2e-ab27-9ab38c8bbdf5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset/train/images/OK_10_png.rf.b236e4abee69b60aed5f1d05cb9b15a0.jpg\n",
            "/content/dataset/train/images/OK_10_png.rf.e4f16c011ee5c500f2af37777c9bef2b.jpg\n",
            "/content/dataset/train/images/OK_29_png.rf.85f62964f22099442f0a434fbbd5e91d.jpg\n",
            "/content/dataset/train/images/OK_3_png.rf.bbc2035d2c4b6fcc44d002c0321ffce9.jpg\n",
            "/content/dataset/train/images/OK_7_png.rf.da35ab4be1a6acd6298460aeb90cd09f.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#yaml 파일 업데이트\n",
        "import yaml\n",
        "with open('/content/dataset/data.yaml', 'r') as f:\n",
        "  data = yaml.safe_load(f)\n",
        "print(data)\n",
        "#'data.yaml' 파일을 읽기 모드로 엽니다.\n",
        "#yaml.safe_load() 함수를 사용하여 파일의 내용을 파싱하여 data 변수에 저장합니다.\n",
        "#data 변수를 출력합니다.\n",
        "#'data.yaml' 파일의 내용이 파싱되어 data 변수에 저장되고, 그 값을 출력합니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV4GqN8-uIui",
        "outputId": "1d2a2af7-acb3-4d77-b55b-3ee846376cc6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': '../train/images', 'val': '../valid/images', 'test': '../test/images', 'nc': 4, 'names': ['NG_L', 'NG_R', 'OK_L', 'OK_R'], 'roboflow': {'workspace': 'hs-esyhr', 'project': 'logo4-yuhxx', 'version': 14, 'license': 'CC BY 4.0', 'url': 'https://universe.roboflow.com/hs-esyhr/logo4-yuhxx/dataset/14'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['train'] = '/content/dataset/train.txt'\n",
        "data['val'] = '/content/dataset/val.txt'\n",
        "with open('/content/dataset/data.yaml', 'w') as f:\n",
        "  yaml.dump(data, f)\n",
        "print(data)\n",
        "#data 딕셔너리에 'train' 키와 '/content/dataset/train.txt' 값을 추가합니다.\n",
        "#data 딕셔너리에 'val' 키와 '/content/dataset/val.txt' 값을 추가합니다.\n",
        "#'data.yaml' 파일을 쓰기 모드로 엽니다.\n",
        "#yaml.dump() 함수를 사용하여 data 딕셔너리를 YAML 형식으로 직렬화하여 파일에 저장합니다.\n",
        "#data 딕셔너리를 출력합니다.\n",
        "#data 딕셔너리에 'train'과 'val' 키가 추가되고, 'data.yaml' 파일에 해당 내용이 저장됩니다.\n",
        "#마지막으로 data 딕셔너리를 출력합니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QbprYbzuIi5",
        "outputId": "e6984d08-c53e-4636-b764-509c0cda22b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': '/content/dataset/train.txt', 'val': '/content/dataset/val.txt', 'test': '../test/images', 'nc': 4, 'names': ['NG_L', 'NG_R', 'OK_L', 'OK_R'], 'roboflow': {'workspace': 'hs-esyhr', 'project': 'logo4-yuhxx', 'version': 14, 'license': 'CC BY 4.0', 'url': 'https://universe.roboflow.com/hs-esyhr/logo4-yuhxx/dataset/14'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat /content/dataset/data.yaml\n",
        "#%cat은 주피터 노트북에서 사용되는 명령어로, 해당 경로의 파일을 출력하는 명령입니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBS9oRw1uuW9",
        "outputId": "0450c127-52b0-494f-a7ce-29e117ecad6e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "names:\n",
            "- NG_L\n",
            "- NG_R\n",
            "- OK_L\n",
            "- OK_R\n",
            "nc: 4\n",
            "roboflow:\n",
            "  license: CC BY 4.0\n",
            "  project: logo4-yuhxx\n",
            "  url: https://universe.roboflow.com/hs-esyhr/logo4-yuhxx/dataset/14\n",
            "  version: 14\n",
            "  workspace: hs-esyhr\n",
            "test: ../test/images\n",
            "train: /content/dataset/train.txt\n",
            "val: /content/dataset/val.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/yolov5/models/yolov5s.yaml\n",
        "#!cat은 주피터 노트북에서 사용되는 명령어로, 해당 경로의 파일을 출력하는 명령입니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh6fesjeuuTI",
        "outputId": "6ae9a473-b0bc-4d97-dae9-028e6167355b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# YOLOv5 🚀 by Ultralytics, AGPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10회 반복학습 실시\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 10 --data /content/dataset/data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name gun_yolov5s_results\n",
        "#YOLOv5를 사용하여 gun_yolov5s_results라는 이름으로 10 에포크 동안 학습을 수행하는 명령입니다.\n",
        "#%cd /content/yolov5/는 현재 작업 디렉토리를 /content/yolov5/로 변경하는 명령입니다.\n",
        "#!python train.py는 YOLOv5의 train.py 스크립트를 실행하여 다음과 같은 옵션으로 학습을 수행하는 명령입니다:\n",
        "#--img 416: 입력 이미지의 크기를 416x416으로 설정합니다.\n",
        "#--batch 16: 배치 크기를 16으로 설정합니다.\n",
        "#--epochs 10: 10 에포크 동안 학습을 수행합니다.\n",
        "#--data /content/dataset/data.yaml: 데이터셋 구성을 정의하는 YAML 파일의 경로를 지정합니다.\n",
        "#--cfg ./models/yolov5s.yaml: 모델 구조를 정의하는 YAML 파일의 경로를 지정합니다.\n",
        "#--weights yolov5s.pt: 사전 학습된 가중치 파일의 경로를 지정합니다.\n",
        "#--name gun_yolov5s_results: 학습 결과를 저장할 디렉토리의 이름을 지정합니다.\n",
        "#YOLOv5 모델이 주어진 데이터셋을 사용하여 학습을 수행하고, gun_yolov5s_results라는 이름의 디렉토리에 학습 결과가 저장됩니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oCJuEaruuO0",
        "outputId": "d4c2ca03-e4ee-4dc6-ddad-d8f11988196f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/yolov5s.yaml, data=/content/dataset/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=gun_yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-212-g9974d51 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 17.2MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 122MB/s] \n",
            "\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train... 210 images, 0 backgrounds, 0 corrupt: 100% 210/210 [00:00<00:00, 1465.51it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/val... 20 images, 0 backgrounds, 0 corrupt: 100% 20/20 [00:00<00:00, 509.81it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/val.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.09 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/gun_yolov5s_results/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/gun_yolov5s_results\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      1.57G     0.1118    0.03008    0.04912         14        416: 100% 14/14 [00:10<00:00,  1.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.83s/it]\n",
            "                   all         20         40     0.0069      0.905     0.0769     0.0263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      1.57G      0.088     0.0351    0.04609          4        416: 100% 14/14 [00:06<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.11it/s]\n",
            "                   all         20         40    0.00716      0.958      0.137     0.0441\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      1.57G      0.074    0.03965     0.0418          4        416: 100% 14/14 [00:04<00:00,  3.12it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.24it/s]\n",
            "                   all         20         40      0.473      0.435      0.313      0.115\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      1.58G    0.06375    0.03525    0.03924          8        416: 100% 14/14 [00:06<00:00,  2.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.58it/s]\n",
            "                   all         20         40      0.338      0.347      0.106      0.036\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      1.58G    0.06057    0.03373    0.03767          7        416: 100% 14/14 [00:05<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.48it/s]\n",
            "                   all         20         40      0.669       0.64      0.495      0.267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      1.58G    0.05366    0.03086    0.03531         10        416: 100% 14/14 [00:05<00:00,  2.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.45it/s]\n",
            "                   all         20         40      0.484      0.661      0.307      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      1.58G    0.05095    0.02936     0.0353          9        416: 100% 14/14 [00:05<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.84it/s]\n",
            "                   all         20         40      0.611      0.618      0.598      0.208\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      1.58G    0.04767    0.02834    0.03407          6        416: 100% 14/14 [00:05<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.54it/s]\n",
            "                   all         20         40      0.596      0.687      0.673      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      1.58G    0.04394     0.0252    0.03289         10        416: 100% 14/14 [00:05<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.67it/s]\n",
            "                   all         20         40      0.656      0.714      0.712      0.284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      1.58G    0.04071    0.02461    0.03241          6        416: 100% 14/14 [00:05<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.94it/s]\n",
            "                   all         20         40      0.711       0.72      0.716      0.474\n",
            "\n",
            "10 epochs completed in 0.021 hours.\n",
            "Optimizer stripped from runs/train/gun_yolov5s_results/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/gun_yolov5s_results/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/gun_yolov5s_results/weights/best.pt...\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.31it/s]\n",
            "                   all         20         40      0.711       0.72      0.716      0.467\n",
            "                  NG_L         20          9      0.421          1      0.782      0.473\n",
            "                  NG_R         20          6          1          0      0.233     0.0914\n",
            "                  OK_L         20         11      0.562          1      0.967      0.708\n",
            "                  OK_R         20         14       0.86      0.879      0.882      0.597\n",
            "Results saved to \u001b[1mruns/train/gun_yolov5s_results\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#결과보기 : tensorboard #10회반복\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/yolov5/runs/\n",
        "#TensorBoard를 사용하여 /content/yolov5/runs/ 디렉토리에 저장된 로그 파일을 시각화하는 명령입니다.\n",
        "#%load_ext tensorboard는 주피터 노트북에서 TensorBoard를 로드하는 명령입니다.\n",
        "#%tensorboard --logdir /content/yolov5/runs/는 TensorBoard를 실행하여 /content/yolov5/runs/ 디렉토리에 저장된 로그 파일을 시각화합니다.\n",
        "#TensorBoard가 실행되고, 해당 디렉토리에 저장된 로그 파일의 시각화 결과를 볼 수 있습니다."
      ],
      "metadata": {
        "id": "Uxyj3ruYuuKr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "outputId": "311138dd-0a48-49a1-8da7-dd9b1ebd9900"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "import os\n",
        "val_img_path = val_img_list[3]\n",
        "val_img_path\n",
        "#주어진 코드는 IPython.display 모듈에서 Image 클래스를 가져와서 사용하고,\n",
        "#os 모듈을 가져온 후 val_img_list에서 3번째 이미지 경로를 val_img_path 변수에 할당하는 코드입니다.\n",
        "#from IPython.display import Image은 IPython 환경에서 이미지를 표시하기 위해 Image 클래스를 가져오는 명령입니다.\n",
        "#import os는 파일 및 디렉토리 관련 작업을 위해 os 모듈을 가져오는 명령입니다.\n",
        "#val_img_path = val_img_list[3]는 val_img_list에서 3번째 이미지 경로를 val_img_path 변수에 할당하는 명령입니다.\n",
        "#위 코드를 실행하면 val_img_list에서 3번째 이미지의 경로가 val_img_path 변수에 저장됩니다."
      ],
      "metadata": {
        "id": "rmVIflXcu4DC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ecc3855-c642-4f60-f562-3d64b446024f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset/valid/images/OK_37_png.rf.0916389045602e4b9bb196c28fe69362.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/gun_yolov5s_results/weights/best.pt --img 416 --conf 0.6 --save-txt --save-crop --save-conf --source /content/dataset/valid/images\n",
        "#주어진 명령어는 detect.py 스크립트를 실행하여 이미지에서 물체를 감지하는 명령입니다.\n",
        "#!python detect.py는 detect.py 스크립트를 파이썬으로 실행하는 명령입니다.\n",
        "#--weights /content/yolov5/runs/train/gun_yolov5s_results/weights/best.pt는 사용할 가중치 파일의 경로를 지정하는 옵션입니다.\n",
        "#--img 416는 입력 이미지의 크기를 416x416으로 설정하는 옵션입니다.\n",
        "#--conf 0.6은 감지된 물체의 신뢰도 임계값을 0.6으로 설정하는 옵션입니다.\n",
        "#--save-txt는 감지된 물체의 좌표를 텍스트 파일로 저장하는 옵션입니다.\n",
        "#--save-crop는 감지된 물체를 잘라내어 이미지 파일로 저장하는 옵션입니다.\n",
        "#--save-conf는 감지된 물체의 신뢰도를 이미지 파일에 표시하는 옵션입니다.\n",
        "#--source /content/dataset/valid/images는 입력 이미지의 경로를 지정하는 옵션입니다.\n",
        "#위 명령을 실행하면 detect.py 스크립트가 실행되고, 지정된 가중치 파일과 입력 이미지를 사용하여 물체를 감지합니다.\n",
        "#감지된 물체의 좌표는 텍스트 파일로 저장되고, 잘라낸 이미지와 신뢰도가 표시된 이미지도 저장됩니다.\n",
        "#입력 이미지는 /content/dataset/valid/images 디렉토리에서 가져옵니다."
      ],
      "metadata": {
        "id": "l_C8drpFu3_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "481fc9a1-9e96-4bff-a5e4-b9e2fbd1d948"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/gun_yolov5s_results/weights/best.pt'], source=/content/dataset/valid/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-212-g9974d51 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/20 /content/dataset/valid/images/NG_11_png.rf.577106dbf30c0b7bb4f712f184a9b699.jpg: 416x416 1 NG_L, 7.4ms\n",
            "image 2/20 /content/dataset/valid/images/NG_16_png.rf.d8e0cf5e259cb2b420f6872f2020af2b.jpg: 416x416 (no detections), 7.4ms\n",
            "image 3/20 /content/dataset/valid/images/NG_18_png.rf.ddee513a2d7132c7b96077b19dc81b32.jpg: 416x416 (no detections), 7.4ms\n",
            "image 4/20 /content/dataset/valid/images/NG_29_png.rf.516a73911e8c0d5689c9472267a901e4.jpg: 416x416 (no detections), 7.4ms\n",
            "image 5/20 /content/dataset/valid/images/NG_31_png.rf.57fc511028c789f491d051ec1065ec99.jpg: 416x416 (no detections), 7.4ms\n",
            "image 6/20 /content/dataset/valid/images/NG_33_png.rf.456a9662e7d0009718c310f907591e6b.jpg: 416x416 (no detections), 7.4ms\n",
            "image 7/20 /content/dataset/valid/images/NG_43_png.rf.b49bad34dd4b344bcfa0b1c433a5b2f5.jpg: 416x416 1 OK_R, 7.4ms\n",
            "image 8/20 /content/dataset/valid/images/NG_46_png.rf.da879bdda51aecf33bf4be889f439d19.jpg: 416x416 (no detections), 7.4ms\n",
            "image 9/20 /content/dataset/valid/images/NG_47_png.rf.7c06c9023854e84f00c2bcb59c1355ec.jpg: 416x416 (no detections), 7.4ms\n",
            "image 10/20 /content/dataset/valid/images/OK_11_png.rf.5bd8b9abd7cce55c2055d179424173e4.jpg: 416x416 (no detections), 7.4ms\n",
            "image 11/20 /content/dataset/valid/images/OK_16_png.rf.0d6ff9a9386e612b8060a24d18528195.jpg: 416x416 1 NG_L, 1 OK_L, 7.4ms\n",
            "image 12/20 /content/dataset/valid/images/OK_24_png.rf.5d44ed02714612807a69ff5ca80d21d0.jpg: 416x416 1 NG_L, 1 OK_L, 7.5ms\n",
            "image 13/20 /content/dataset/valid/images/OK_2_png.rf.f3a4a4f0babef43e265284774ebd2508.jpg: 416x416 1 NG_L, 1 OK_L, 7.4ms\n",
            "image 14/20 /content/dataset/valid/images/OK_33_png.rf.025ab68958b32519bb29eee56c53020c.jpg: 416x416 1 OK_L, 7.4ms\n",
            "image 15/20 /content/dataset/valid/images/OK_35_png.rf.67b1990eb1085f0847053d35b17f65cd.jpg: 416x416 (no detections), 7.4ms\n",
            "image 16/20 /content/dataset/valid/images/OK_37_png.rf.0916389045602e4b9bb196c28fe69362.jpg: 416x416 (no detections), 8.7ms\n",
            "image 17/20 /content/dataset/valid/images/OK_40_png.rf.22989ef97f2c2838e85b25b490f4e66a.jpg: 416x416 1 OK_L, 7.4ms\n",
            "image 18/20 /content/dataset/valid/images/OK_48_png.rf.6a9a8ee2a556ba3d24211f2174eaa001.jpg: 416x416 1 OK_L, 7.4ms\n",
            "image 19/20 /content/dataset/valid/images/OK_49_png.rf.ef11537714fd45834c020b96fab500f3.jpg: 416x416 (no detections), 7.4ms\n",
            "image 20/20 /content/dataset/valid/images/OK_50_png.rf.98a7473b382a84230de248853cbe0412.jpg: 416x416 1 NG_L, 1 OK_L, 7.4ms\n",
            "Speed: 0.3ms pre-process, 7.5ms inference, 0.8ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n",
            "9 labels saved to runs/detect/exp/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/1backup/best.pt --img 416 --conf 0.6 --save-txt --save-crop --save-conf --source val_img_list[9]\n",
        "#주어진 명령어는 detect.py 스크립트를 실행하여 이미지에서 물체를 감지하는 명령입니다.\n",
        "#!python detect.py는 detect.py 스크립트를 파이썬으로 실행하는 명령입니다.\n",
        "#--weights /content/drive/MyDrive/1backup/best.pt는 사용할 가중치 파일의 경로를 지정하는 옵션입니다.\n",
        "#--img 416는 입력 이미지의 크기를 416x416으로 설정하는 옵션입니다.\n",
        "#--conf 0.6은 감지된 물체의 신뢰도 임계값을 0.6으로 설정하는 옵션입니다.\n",
        "#--save-txt는 감지된 물체의 좌표를 텍스트 파일로 저장하는 옵션입니다.\n",
        "#--save-crop는 감지된 물체를 잘라내어 이미지 파일로 저장하는 옵션입니다.\n",
        "#--save-conf는 감지된 물체의 신뢰도를 이미지 파일에 표시하는 옵션입니다.\n",
        "#--source val_img_list[29]는 입력 이미지의 경로를 val_img_list의 29번째 이미지로 지정하는 옵션입니다.\n",
        "#위 명령을 실행하면 detect.py 스크립트가 실행되고, 지정된 가중치 파일과 입력 이미지를 사용하여 물체를 감지합니다.\n",
        "#감지된 물체의 좌표는 텍스트 파일로 저장되고, 잘라낸 이미지와 신뢰도가 표시된 이미지도 저장됩니다.\n",
        "#입력 이미지는 val_img_list의 29번째 이미지로 지정됩니다."
      ],
      "metadata": {
        "id": "26Gfb-qzu34-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388250b5-fbf3-4b25-f5c9-331118da6cb1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/1backup/best.pt'], source=val_img_list[9], data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-212-g9974d51 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/detect.py\", line 262, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/detect.py\", line 257, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/detect.py\", line 99, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "  File \"/content/yolov5/models/common.py\", line 356, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "  File \"/content/yolov5/models/experimental.py\", line 79, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 791, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 271, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 252, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/1backup/best.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_img_list[4]\n",
        "#val_img_list[4]는 변수나 리스트의 인덱스를 나타내는 표현입니다.\n",
        "#따라서 val_img_list라는 리스트에서 4번째 요소를 의미합니다."
      ],
      "metadata": {
        "id": "tJNu6DmJu316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85bf69b4-19cf-47d5-8447-5bd004b85991"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset/valid/images/NG_47_png.rf.7c06c9023854e84f00c2bcb59c1355ec.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_img_path = val_img_list[4]\n",
        "img_file = os.path.join('/content/dataset/valid/images/', os.path.basename(val_img_path))\n",
        "Image(img_file)\n",
        "#val_img_list[4]는 val_img_list 리스트에서 4번째 요소를 의미합니다. 이 요소는 val_img_path 변수에 저장됩니다.\n",
        "#그 다음, img_file 변수는 val_img_path를 기반으로 생성됩니다.\n",
        "#os.path.basename(val_img_path)는 val_img_path의 파일 이름 부분을 추출하는 것을 의미합니다.\n",
        "#그리고 '/content/dataset/valid/images/'와 결합하여 이미지 파일의 전체 경로를 생성합니다.\n",
        "#마지막으로, Image(img_file)는 img_file 경로에 있는 이미지를 로드하여 보여줍니다."
      ],
      "metadata": {
        "id": "hxm8Y7Jlu3yS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "0ebfc319-746a-4e69-8f25-9ae76219e11e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_file\n",
        "#이미지 파일의 전체 경로를 나타냅니다"
      ],
      "metadata": {
        "id": "PPwYEpACu3vF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb7cfa64-ef7d-4c7d-b385-04b40c4ab345"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset/valid/images/NG_47_png.rf.7c06c9023854e84f00c2bcb59c1355ec.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/1backup/best.pt --img 416 --conf 0.6 --save-txt --save-crop --save-conf --source {img_file}\n",
        "#detect.py 스크립트를 실행하여 객체 감지를 수행하는 명령어입니다.\n",
        "#--weights: 객체 감지에 사용할 모델의 가중치 파일 경로를 지정합니다.\n",
        "#--img: 입력 이미지의 크기를 지정합니다.\n",
        "#--conf: 객체를 감지하기 위한 최소 신뢰도(confidence) 임계값을 지정합니다.\n",
        "#--save-txt: 객체 감지 결과를 텍스트 파일로 저장할지 여부를 지정합니다.\n",
        "#--save-crop: 객체 감지된 영역을 잘라내어 저장할지 여부를 지정합니다.\n",
        "#--save-conf: 객체 감지 결과의 신뢰도를 저장할지 여부를 지정합니다.\n",
        "#--source: 객체 감지를 수행할 이미지 파일의 경로를 지정합니다.\n",
        "#{img_file} 변수를 사용하여 동적으로 이미지 파일 경로를 지정하고 있습니다.\n",
        "#img_file 변수에는 객체 감지를 수행할 이미지 파일의 전체 경로가 들어가야 합니다."
      ],
      "metadata": {
        "id": "ozdN1CjOvcny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b332e6-c679-4826-a0c6-34d238be6671"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/1backup/best.pt'], source=/content/dataset/valid/images/NG_47_png.rf.7c06c9023854e84f00c2bcb59c1355ec.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-212-g9974d51 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/detect.py\", line 262, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/detect.py\", line 257, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/detect.py\", line 99, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "  File \"/content/yolov5/models/common.py\", line 356, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "  File \"/content/yolov5/models/experimental.py\", line 79, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 791, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 271, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 252, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/1backup/best.pt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = '/content/dataset/valid/images/OK_11_png.rf.c06d70475ce8ea9bbfa5513b1f140669.jpg'\n",
        "Image(output)\n",
        "#주어진 코드는 output 변수에 저장된 이미지 파일을 로드하여 출력하는 것입니다.\n",
        "#Image 클래스는 이미지 파일을 로드하고 표시하는 데 사용됩니다.\n",
        "#output 변수에 저장된 이미지 파일이 로드되어 출력됩니다."
      ],
      "metadata": {
        "id": "04qhCZ5Gvck4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "outputId": "edd12dde-1e5b-42b9-fccc-abba09df637b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1289\u001b[0m             \u001b[0mmimetype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mimetype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1290\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malways_both\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1291\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m                 \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '/content/dataset/valid/images/OK_11_png.rf.c06d70475ce8ea9bbfa5513b1f140669.jpg'"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_png_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FMT_PNG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_and_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_jpeg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m_data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mb64_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2a_base64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m             raise FileNotFoundError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m                 \"No such file or directory: '%s'\" % (self.data))\n\u001b[1;32m   1304\u001b[0m         \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '/content/dataset/valid/images/OK_11_png.rf.c06d70475ce8ea9bbfa5513b1f140669.jpg'"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 100 --data /content/dataset/data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name gun_yolov5s_results\n",
        "#주어진 코드는 yolov5 디렉토리로 이동한 후, train.py 스크립트를 실행하여 객체 감지 모델을 학습하는 명령어입니다.\n",
        "#--img: 입력 이미지의 크기를 지정합니다.\n",
        "#--batch: 학습에 사용할 배치 크기를 지정합니다.\n",
        "#--epochs: 학습할 에폭(epoch) 수를 지정합니다.\n",
        "#--data: 데이터셋에 대한 YAML 파일의 경로를 지정합니다.\n",
        "#--cfg: 모델 구성 파일의 경로를 지정합니다.\n",
        "#--weights: 사전 학습된 모델의 가중치 파일 경로를 지정합니다.\n",
        "#--name: 학습 결과를 저장할 디렉토리 이름을 지정합니다.\n",
        "#yolov5 디렉토리로 이동한 후, 주어진 옵션과 함께 train.py 스크립트를 실행하여 객체 감지 모델을 학습할 수 있습니다."
      ],
      "metadata": {
        "id": "koCWFo0dvcfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61509ee-3148-43dc-ad98-89200dd8c7c0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/yolov5s.yaml, data=/content/dataset/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=gun_yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-212-g9974d51 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "YOLOv5s summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train.cache... 210 images, 0 backgrounds, 0 corrupt: 100% 210/210 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/val.cache... 20 images, 0 backgrounds, 0 corrupt: 100% 20/20 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.09 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/gun_yolov5s_results2/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/gun_yolov5s_results2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      1.57G     0.1118    0.03008    0.04912         14        416: 100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.39it/s]\n",
            "                   all         20         40     0.0069      0.905     0.0769     0.0263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99      1.57G    0.08748    0.03523    0.04603          4        416: 100% 14/14 [00:06<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.23it/s]\n",
            "                   all         20         40    0.00701      0.958      0.135     0.0436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99      1.57G    0.07371    0.03925    0.04148          4        416: 100% 14/14 [00:04<00:00,  2.86it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.32it/s]\n",
            "                   all         20         40      0.576      0.111        0.1     0.0278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99      1.58G    0.06443     0.0334     0.0388          8        416: 100% 14/14 [00:06<00:00,  2.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.50it/s]\n",
            "                   all         20         40      0.394      0.679      0.322     0.0901\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99      1.58G    0.06187    0.03142    0.03645          7        416: 100% 14/14 [00:04<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.25it/s]\n",
            "                   all         20         40      0.491      0.496      0.302      0.146\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99      1.58G    0.06372    0.02758    0.03363         10        416: 100% 14/14 [00:06<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.31it/s]\n",
            "                   all         20         40       0.48      0.615      0.497      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99      1.58G    0.05897    0.02744    0.03351         62        416:  86% 12/14 [00:04<00:00,  2.75it/s]\n",
            "Error in sys.excepthook:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/dask/base.py\", line 68, in wrapper\n",
            "    @wraps(func)\n",
            "KeyboardInterrupt\n",
            "\n",
            "Original exception was:\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/train.py\", line 647, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/train.py\", line 536, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/content/yolov5/train.py\", line 291, in train\n",
            "    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1182, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/content/yolov5/utils/dataloaders.py\", line 172, in __iter__\n",
            "    yield next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1328, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1284, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1132, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/queue.py\", line 180, in get\n",
            "    self.not_empty.wait(remaining)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 324, in wait\n",
            "    gotit = waiter.acquire(True, timeout)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#결과보기 : tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/yolov5/runs/\n",
        "#주어진 코드는 tensorboard를 사용하여 학습 로그를 시각화하는 명령어입니다.\n",
        "#tensorboard를 활성화\n",
        "#--logdir 옵션을 사용하여 로그 파일이 있는 디렉토리 경로를 지정합니다."
      ],
      "metadata": {
        "id": "ySuAbHkzvcce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "6d19ae0c-6b37-4ac8-fcd8-d6c2c2776fba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "import os\n",
        "val_img_path = val_img_list[3]\n",
        "val_img_path\n",
        "#주어진 코드는 IPython.display 모듈에서 Image 클래스를 가져오고,\n",
        "#os 모듈을 가져온 후, val_img_list에서 4번째 이미지 경로를 val_img_path 변수에 저장하는 것입니다.\n",
        "#val_img_list는 이미지 파일 경로의 리스트로 가정되며, 여기서 4번째 이미지 경로를 val_img_path 변수에 저장합니다.\n",
        "#이후 val_img_path를 출력합니다."
      ],
      "metadata": {
        "id": "CtQNuiUqvcZd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aea8e9c4-6912-4460-b5b2-135a6b6864e9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset/valid/images/OK_37_png.rf.0916389045602e4b9bb196c28fe69362.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/gun_yolov5s_results2/weights/best.pt --img 416 --conf 0.6 --save-txt --save-crop --save-conf --source /content/dataset/valid/images\n",
        "#주어진 코드는 detect.py 스크립트를 사용하여 이미지에서 물체를 감지하는 명령어입니다.\n",
        "#--weights 옵션은 학습된 모델의 가중치 파일 경로를 지정합니다.\n",
        "#--img 옵션은 입력 이미지의 크기를 지정합니다.\n",
        "#--conf 옵션은 감지 임계값을 지정합니다.\n",
        "#--save-txt, --save-crop, --save-conf 옵션은 각각 감지된 물체의 좌표를 텍스트 파일로 저장하고, 감지된 물체를 잘라내어 저장하며, 감지된 물체의 신뢰도를 저장하는 옵션입니다.\n",
        "#--source 옵션은 입력 이미지의 경로를 지정합니다.\n",
        "#/content/yolov5/runs/train/gun_yolov5s_results2/weights/best.pt 가중치를 사용하여 크기가 416인 이미지에서 물체를 감지하고,\n",
        "#감지된 결과를 텍스트 파일과 잘라낸 이미지로 저장하며, 감지된 물체의 신뢰도를 저장합니다.\n",
        "#입력 이미지는 /content/dataset/valid/images 경로에 있습니다."
      ],
      "metadata": {
        "id": "KCoX1NOrvcWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f77b2e3-5140-46de-bdbe-97ad230ce22c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/gun_yolov5s_results2/weights/best.pt'], source=/content/dataset/valid/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-212-g9974d51 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/20 /content/dataset/valid/images/NG_11_png.rf.577106dbf30c0b7bb4f712f184a9b699.jpg: 416x416 (no detections), 7.4ms\n",
            "image 2/20 /content/dataset/valid/images/NG_16_png.rf.d8e0cf5e259cb2b420f6872f2020af2b.jpg: 416x416 (no detections), 7.4ms\n",
            "image 3/20 /content/dataset/valid/images/NG_18_png.rf.ddee513a2d7132c7b96077b19dc81b32.jpg: 416x416 (no detections), 7.4ms\n",
            "image 4/20 /content/dataset/valid/images/NG_29_png.rf.516a73911e8c0d5689c9472267a901e4.jpg: 416x416 1 NG_L, 7.4ms\n",
            "image 5/20 /content/dataset/valid/images/NG_31_png.rf.57fc511028c789f491d051ec1065ec99.jpg: 416x416 (no detections), 7.4ms\n",
            "image 6/20 /content/dataset/valid/images/NG_33_png.rf.456a9662e7d0009718c310f907591e6b.jpg: 416x416 (no detections), 7.4ms\n",
            "image 7/20 /content/dataset/valid/images/NG_43_png.rf.b49bad34dd4b344bcfa0b1c433a5b2f5.jpg: 416x416 (no detections), 7.4ms\n",
            "image 8/20 /content/dataset/valid/images/NG_46_png.rf.da879bdda51aecf33bf4be889f439d19.jpg: 416x416 (no detections), 7.4ms\n",
            "image 9/20 /content/dataset/valid/images/NG_47_png.rf.7c06c9023854e84f00c2bcb59c1355ec.jpg: 416x416 (no detections), 7.4ms\n",
            "image 10/20 /content/dataset/valid/images/OK_11_png.rf.5bd8b9abd7cce55c2055d179424173e4.jpg: 416x416 (no detections), 7.4ms\n",
            "image 11/20 /content/dataset/valid/images/OK_16_png.rf.0d6ff9a9386e612b8060a24d18528195.jpg: 416x416 (no detections), 7.4ms\n",
            "image 12/20 /content/dataset/valid/images/OK_24_png.rf.5d44ed02714612807a69ff5ca80d21d0.jpg: 416x416 (no detections), 7.4ms\n",
            "image 13/20 /content/dataset/valid/images/OK_2_png.rf.f3a4a4f0babef43e265284774ebd2508.jpg: 416x416 (no detections), 7.4ms\n",
            "image 14/20 /content/dataset/valid/images/OK_33_png.rf.025ab68958b32519bb29eee56c53020c.jpg: 416x416 (no detections), 7.4ms\n",
            "image 15/20 /content/dataset/valid/images/OK_35_png.rf.67b1990eb1085f0847053d35b17f65cd.jpg: 416x416 (no detections), 7.7ms\n",
            "image 16/20 /content/dataset/valid/images/OK_37_png.rf.0916389045602e4b9bb196c28fe69362.jpg: 416x416 (no detections), 7.4ms\n",
            "image 17/20 /content/dataset/valid/images/OK_40_png.rf.22989ef97f2c2838e85b25b490f4e66a.jpg: 416x416 (no detections), 7.4ms\n",
            "image 18/20 /content/dataset/valid/images/OK_48_png.rf.6a9a8ee2a556ba3d24211f2174eaa001.jpg: 416x416 (no detections), 7.4ms\n",
            "image 19/20 /content/dataset/valid/images/OK_49_png.rf.ef11537714fd45834c020b96fab500f3.jpg: 416x416 (no detections), 7.4ms\n",
            "image 20/20 /content/dataset/valid/images/OK_50_png.rf.98a7473b382a84230de248853cbe0412.jpg: 416x416 (no detections), 7.4ms\n",
            "Speed: 0.3ms pre-process, 7.4ms inference, 0.7ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp4\u001b[0m\n",
            "1 labels saved to runs/detect/exp4/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_img_list[3]\n",
        "#val_img_list라는 리스트에서 인덱스 3에 해당하는 요소를 가져오는 것"
      ],
      "metadata": {
        "id": "--QeCRKFvcT8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a45251e2-d7d8-4b46-8c91-30e22052a7d0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/dataset/valid/images/OK_37_png.rf.0916389045602e4b9bb196c28fe69362.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/gun_yolov5s_results2/weights/best.pt --img 416 --conf 0.6 --save-txt --save-crop --save-conf --source {img_file}\n",
        "#주어진 코드는 detect.py 스크립트를 사용하여 이미지에서 물체를 감지하는 명령어입니다.\n",
        "#--weights 옵션은 학습된 모델의 가중치 파일 경로를 지정합니다.\n",
        "#--img 옵션은 입력 이미지의 크기를 지정합니다.\n",
        "#--conf 옵션은 감지 임계값을 지정합니다.\n",
        "#--save-txt, --save-crop, --save-conf 옵션은 각각 감지된 물체의 좌표를 텍스트 파일로 저장하고, 감지된 물체를 잘라내어 저장하며, 감지된 물체의 신뢰도를 저장하는 옵션입니다.\n",
        "#--source 옵션은 입력 이미지의 경로를 지정합니다.\n",
        "#{img_file}은 변수나 파일 경로를 나타내는 것으로 추정됩니다. 실제로 사용할 때는 해당 변수나 파일 경로로 대체되어야 합니다.\n",
        "#/content/yolov5/runs/train/gun_yolov5s_results2/weights/best.pt 가중치를 사용하여 크기가 416인 이미지에서 물체를 감지하고,\n",
        "#감지된 결과를 텍스트 파일과 잘라낸 이미지로 저장하며, 감지된 물체의 신뢰도를 저장합니다.\n",
        "#입력 이미지는 {img_file} 경로에 있어야 합니다."
      ],
      "metadata": {
        "id": "8uwQzKH5vcRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f4fc286-93f3-446c-b8ed-330e155aa112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/gun_yolov5s_results2/weights/best.pt'], source=/content/dataset/valid/images/NG_47_png.rf.7c06c9023854e84f00c2bcb59c1355ec.jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-212-g9974d51 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = '/content/yolov5/runs/detect/exp4/OK_11_png.rf.c06d70475ce8ea9bbfa5513b1f140669.jpg'\n",
        "Image(output)\n",
        "#output 변수에 저장된 이미지 파일을 로드하여 출력하는 것입니다.\n",
        "#Image(output)는 PIL 라이브러리의 Image 클래스를 사용하여 해당 이미지 파일을 로드하고 출력하는 것입니다."
      ],
      "metadata": {
        "id": "mzqHXEmevcOE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}